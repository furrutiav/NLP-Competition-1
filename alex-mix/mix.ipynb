{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Remix"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Windows\n",
      "[nltk_data]     10\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Windows\n",
      "[nltk_data]     10\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\wordnet.zip.\n",
      "[nltk_data] Downloading package opinion_lexicon to C:\\Users\\Windows\n",
      "[nltk_data]     10\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\opinion_lexicon.zip.\n",
      "[nltk_data] Downloading package sentiwordnet to C:\\Users\\Windows\n",
      "[nltk_data]     10\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\sentiwordnet.zip.\n",
      "[nltk_data] Downloading package omw-1.4 to C:\\Users\\Windows\n",
      "[nltk_data]     10\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\omw-1.4.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.2.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.2.0/en_core_web_sm-3.2.0-py3-none-any.whl (13.9 MB)\n",
      "Requirement already satisfied: spacy<3.3.0,>=3.2.0 in f:\\desktop\\universidad\\lenguaje\\nlp-competition-1\\venv\\lib\\site-packages (from en-core-web-sm==3.2.0) (3.2.4)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in f:\\desktop\\universidad\\lenguaje\\nlp-competition-1\\venv\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.0.6)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in f:\\desktop\\universidad\\lenguaje\\nlp-competition-1\\venv\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.0.7)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in f:\\desktop\\universidad\\lenguaje\\nlp-competition-1\\venv\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.0.6)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in f:\\desktop\\universidad\\lenguaje\\nlp-competition-1\\venv\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (4.63.1)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in f:\\desktop\\universidad\\lenguaje\\nlp-competition-1\\venv\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.9.1)\n",
      "Requirement already satisfied: packaging>=20.0 in f:\\desktop\\universidad\\lenguaje\\nlp-competition-1\\venv\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (21.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in f:\\desktop\\universidad\\lenguaje\\nlp-competition-1\\venv\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.4.2)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in f:\\desktop\\universidad\\lenguaje\\nlp-competition-1\\venv\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (8.0.15)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in f:\\desktop\\universidad\\lenguaje\\nlp-competition-1\\venv\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.7.7)\n",
      "Requirement already satisfied: jinja2 in f:\\desktop\\universidad\\lenguaje\\nlp-competition-1\\venv\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.1.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in f:\\desktop\\universidad\\lenguaje\\nlp-competition-1\\venv\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.3.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in f:\\desktop\\universidad\\lenguaje\\nlp-competition-1\\venv\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.0.6)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in f:\\desktop\\universidad\\lenguaje\\nlp-competition-1\\venv\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.8.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in f:\\desktop\\universidad\\lenguaje\\nlp-competition-1\\venv\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.0.9)\n",
      "Requirement already satisfied: numpy>=1.15.0 in f:\\desktop\\universidad\\lenguaje\\nlp-competition-1\\venv\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.22.3)\n",
      "Requirement already satisfied: click<8.1.0 in f:\\desktop\\universidad\\lenguaje\\nlp-competition-1\\venv\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (8.0.4)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in f:\\desktop\\universidad\\lenguaje\\nlp-competition-1\\venv\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.0.2)\n",
      "Requirement already satisfied: setuptools in f:\\desktop\\universidad\\lenguaje\\nlp-competition-1\\venv\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (61.3.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in f:\\desktop\\universidad\\lenguaje\\nlp-competition-1\\venv\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.27.1)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in f:\\desktop\\universidad\\lenguaje\\nlp-competition-1\\venv\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.4.1)\n",
      "Requirement already satisfied: pathy>=0.3.5 in f:\\desktop\\universidad\\lenguaje\\nlp-competition-1\\venv\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.6.1)\n",
      "Requirement already satisfied: colorama in f:\\desktop\\universidad\\lenguaje\\nlp-competition-1\\venv\\lib\\site-packages (from click<8.1.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.4.4)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in f:\\desktop\\universidad\\lenguaje\\nlp-competition-1\\venv\\lib\\site-packages (from packaging>=20.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.0.7)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in f:\\desktop\\universidad\\lenguaje\\nlp-competition-1\\venv\\lib\\site-packages (from pathy>=0.3.5->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in f:\\desktop\\universidad\\lenguaje\\nlp-competition-1\\venv\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (4.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in f:\\desktop\\universidad\\lenguaje\\nlp-competition-1\\venv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.26.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in f:\\desktop\\universidad\\lenguaje\\nlp-competition-1\\venv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in f:\\desktop\\universidad\\lenguaje\\nlp-competition-1\\venv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in f:\\desktop\\universidad\\lenguaje\\nlp-competition-1\\venv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.0.12)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in f:\\desktop\\universidad\\lenguaje\\nlp-competition-1\\venv\\lib\\site-packages (from jinja2->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.1.1)\n",
      "[+] Download and installation successful\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.1.2; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the 'F:\\Desktop\\Universidad\\Lenguaje\\NLP-Competition-1\\venv\\Scripts\\python.exe -m pip install --upgrade pip' command.\n",
      "Some weights of the model checkpoint at vinai/bertweet-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.decoder.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "emoji is not installed, thus not converting emoticons or emojis into text. Please install emoji: pip3 install emoji\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import re\n",
    "import spacy\n",
    "import torch\n",
    "import emojilib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('opinion_lexicon')\n",
    "nltk.download(\"sentiwordnet\")\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "from nltk.corpus import opinion_lexicon\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from unidecode import unidecode\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from sklearn.metrics import cohen_kappa_score, accuracy_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from nltk import bigrams\n",
    "from nltk import trigrams\n",
    "\n",
    "!python -m spacy download en_core_web_sm\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "tweet_tokenizer = TweetTokenizer()\n",
    "bertweet = AutoModel.from_pretrained(\"vinai/bertweet-base\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"vinai/bertweet-base\", use_fast=False, normalization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "SENTIMENTS = \"anger fear joy sadness\".split()\n",
    "DF_TRAIN = pickle.load(open(\"df_train.pickle\", \"rb\"))\n",
    "INTENSITIES = \"low medium high\".split()\n",
    "VOWELS = \"aeiou\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Representaciones"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "outputs": [],
   "source": [
    "LABELS = \"lemma pos tag shape\".split()\n",
    "\n",
    "def get_emojilib_attrib(tweet: str) -> dict[str, int]:\n",
    "    result = {}\n",
    "    emo_list = emojilib.emoji_list(tweet)\n",
    "    emo_names = list([d['name'] for d in emo_list if 'name' in d])\n",
    "    for emo in emo_names:\n",
    "        if emo not in result.keys():\n",
    "            result[\"emoji<&>\" + emo] = 0\n",
    "        result[\"emoji<&>\" + emo] += 1\n",
    "    return result\n",
    "\n",
    "\n",
    "def get_linguistics_attrib(tweet: str) -> dict[str, int]:\n",
    "    result = {}\n",
    "    nlp_tweet = nlp(tweet)\n",
    "    for token in nlp_tweet:\n",
    "        vals = [token.lemma_.lower(), token.pos_, token.tag_, token.shape_]\n",
    "        for k, v in zip(LABELS, vals):\n",
    "            ling = f\"linguistics<&>{k}<&>{v}\"\n",
    "            if ling not in result.keys():\n",
    "                result[ling] = 0\n",
    "            result[ling] += 1\n",
    "        vals = [token.ent_id_, token.ent_type_]\n",
    "        for k, v in zip([\"name\", \"label\"], vals):\n",
    "            ling = f\"entities<&>{k}<&>{v}\"\n",
    "            if ling not in result.keys():\n",
    "                result[ling] = 0\n",
    "            result[ling] += 1\n",
    "\n",
    "    def not_stop(tup: tuple) -> bool:\n",
    "        for element in tup:\n",
    "            if element.is_stop:\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    bi_tokens = [(w[0].lemma_.lower(), w[1].lemma_.lower()) for w in bigrams(nlp_tweet) if not_stop(w)]\n",
    "    for bigram in bi_tokens:\n",
    "        ling = f\"linguistics<&>bigram<&>{bigram}\"\n",
    "        if ling not in result.keys():\n",
    "            result[ling] = 0\n",
    "        result[ling] += 1\n",
    "    tri_tokens = [(w[0].lemma_.lower(), w[1].lemma_.lower()) for w in trigrams(nlp_tweet) if not_stop(w)]\n",
    "    for trigram in tri_tokens:\n",
    "        ling = f\"linguistics<&>trigram<&>{trigram}\"\n",
    "        if ling not in result.keys():\n",
    "            result[ling] = 0\n",
    "        result[ling] += 1\n",
    "    return result\n",
    "\n",
    "\n",
    "def get_punct_attrib(tweet: str) -> dict[str, int]:\n",
    "    result = {\n",
    "        \"punct<&>[\\.]{3}\": len(re.findall(r\"[.]{3}\", tweet)), \"punct<&>[!]\": len(re.findall(r\"[!]\", tweet)),\n",
    "        \"punct<&>[#]\": len(re.findall(r\"[#]\", tweet)), \"punct<&>[#]{1}\\S+\": len(re.findall(r\"[#]\\S+\", tweet)),\n",
    "        \"punct<&>[\\*]\": len(re.findall(r\"[*]\", tweet)), \"punct<&>[@]{1}\\S+\": len(re.findall(r\"[@]\\S+\", tweet)),\n",
    "        \"punct<&>\\S*[?]{1}\\S*\": len(re.findall(r\"\\S*[?]\\S*\", tweet))\n",
    "    }\n",
    "    return result\n",
    "\n",
    "\n",
    "def get_retro_attrib(tweet: str) -> dict[str, int]:\n",
    "    result = {\n",
    "        \"retro<&>num_tokens\": len(tweet.split()), \"retro<&>length\": len(\" \".join(tweet.split())),\n",
    "        \"retro<&>num_numbs\": len(re.findall(r\"\\d+\", tweet)), \"retro<&>num_alpha\": len(re.findall(r\"\\w+\", tweet)),\n",
    "        \"retro<&>num_with_uppercase\": len(re.findall(r\"\\S*[A-Z]+\\S*\", tweet)),\n",
    "        \"retro<&>num_tokens_upper\": sum(int(t.isupper()) for t in tweet.split())\n",
    "    }\n",
    "\n",
    "    def prop_vowels(text: str) -> float:\n",
    "        length = len(text.replace(\" \", \"\"))\n",
    "        if length > 0:\n",
    "            return len(re.findall(r\"[aeiou]\", text)) / length\n",
    "        return 0\n",
    "\n",
    "    def len_max_rep_char(text: str) -> int:\n",
    "        extended_text = text + \" \"\n",
    "        lens = [0]\n",
    "        character_len = 1\n",
    "        current= extended_text[0]\n",
    "        for character in extended_text[1:]:\n",
    "            if character == current:\n",
    "                character_len += 1\n",
    "                continue\n",
    "            if current.isalpha():\n",
    "                lens.append(character_len)\n",
    "            current = character\n",
    "            character_len = 1\n",
    "        return max(lens)\n",
    "\n",
    "    def max_char_fre_per_token(text: str, character=\"k\") -> int:\n",
    "        tokens = text.split()\n",
    "        max_freq = 0\n",
    "        for token in tokens:\n",
    "            freq = sum(int(c == character) for c in token)\n",
    "            if freq > max_freq:\n",
    "                max_freq = freq\n",
    "        return max_freq\n",
    "\n",
    "    def max_type_rep_char_per_token(text: str, kind=VOWELS) -> int:\n",
    "        extended_text = unidecode(text + \" \")\n",
    "        lens = [0]\n",
    "        character_len = 1\n",
    "        current = extended_text[0]\n",
    "        for character in extended_text[1:]:\n",
    "            current_is_vowel = current in VOWELS\n",
    "            if current.isalpha() and character.isalpha() and ((character in VOWELS and current_is_vowel) or (character not in VOWELS and not current_is_vowel)):\n",
    "                character_len += 1\n",
    "                continue\n",
    "            if kind == VOWELS:\n",
    "                if current_is_vowel:\n",
    "                    lens.append(character_len)\n",
    "            elif not current_is_vowel:\n",
    "                lens.append(character_len)\n",
    "            current = character\n",
    "            character_len = 1\n",
    "        return max(lens)\n",
    "\n",
    "    lower_tweet = tweet.lower()\n",
    "    result[\"retro<&>prop_vowels\"] = prop_vowels(lower_tweet)\n",
    "    result[\"retro<&>len_max_rep_char\"] = len_max_rep_char(lower_tweet)\n",
    "    result[\"retro<&>max_char_fre_per_token(o)\"] = max_char_fre_per_token(lower_tweet, character=\"o\")\n",
    "    result[\"retro<&>max_char_fre_per_token(s)\"] = max_char_fre_per_token(lower_tweet, character=\"s\")\n",
    "    result[\"retro<&>max_char_fre_per_token(g)\"] = max_char_fre_per_token(lower_tweet, character=\"g\")\n",
    "    result[\"retro<&>max_char_fre_per_token(l)\"] = max_char_fre_per_token(lower_tweet, character=\"l\")\n",
    "    result[\"retro<&>max_type_rep_char_per_token(vowel)\"] = max_type_rep_char_per_token(lower_tweet)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def get_sentiwordnet_sent(tweet: str):\n",
    "    def penn_to_wn(tag: str):\n",
    "        if tag.startswith('J'):\n",
    "            return wn.ADJ\n",
    "        elif tag.startswith('N'):\n",
    "            return wn.NOUN\n",
    "        elif tag.startswith('R'):\n",
    "            return wn.ADV\n",
    "        elif tag.startswith('V'):\n",
    "            return wn.VERB\n",
    "        return None\n",
    "\n",
    "    def get_sentiment(word: str, tag: str):\n",
    "        wn_tag = penn_to_wn(tag)\n",
    "        if wn_tag not in (wn.NOUN, wn.ADJ, wn.ADV):\n",
    "            return [0, 0, 0]\n",
    "        lemma = lemmatizer.lemmatize(word, pos=wn_tag)\n",
    "        if not lemma:\n",
    "            return [0, 0, 0]\n",
    "        synsets = wn.synsets(word, pos=wn_tag)\n",
    "        if not synsets:\n",
    "            return [0, 0, 0]\n",
    "        swn_synset = swn.senti_synset(synsets[0].name())\n",
    "        return [swn_synset.pos_score(), swn_synset.neg_score(), swn_synset.obj_score()]\n",
    "\n",
    "    words_data = tweet_tokenizer.tokenize(tweet.lower())\n",
    "\n",
    "    pos_val = nltk.pos_tag(words_data)\n",
    "    senti_val = [get_sentiment(x, y) for (x, y) in pos_val]\n",
    "    return dict(zip(\"+ - o\".split(), np.sum(senti_val, axis=0)))\n",
    "\n",
    "\n",
    "def get_lexicon_attrib(tweet: str) -> dict[str, any]:\n",
    "    result = {}\n",
    "    sentiwordnet = get_sentiwordnet_sent(tweet)\n",
    "    result[\"lexicon<&>LiuHu<&>+\"] = sum(int(t.lower() in opinion_lexicon.positive()) for t in tweet.split())\n",
    "    result[\"lexicon<&>LiuHu<&>-\"] = sum(int(t.lower() in opinion_lexicon.negative()) for t in tweet.split())\n",
    "    result[\"lexicon<&>sentiwordnet<&>+\"] = sentiwordnet[\"+\"]\n",
    "    result[\"lexicon<&>sentiwordnet<&>-\"] = sentiwordnet[\"-\"]\n",
    "    result[\"lexicon<&>sentiwordnet<&>o\"] = sentiwordnet[\"o\"]\n",
    "    return result"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "outputs": [],
   "source": [
    "def get_first_representation(cut_below=5) -> pd.DataFrame:\n",
    "    attributes = []\n",
    "    for idx in DF_TRAIN.index:\n",
    "        tweet = DF_TRAIN.loc[idx][\"text\"]\n",
    "        o = {\"id\": idx}\n",
    "        o = {**o, **get_retro_attrib(tweet)}\n",
    "        o = {**o, **get_punct_attrib(tweet)}\n",
    "        o = {**o, **get_emojilib_attrib(tweet)}\n",
    "        o = {**o, **get_linguistics_attrib(tweet)}\n",
    "        attributes.append(o)\n",
    "    sparse_result = pd.DataFrame(attributes).set_index(\"id\").fillna(0)\n",
    "    to_drop = []\n",
    "    for col in sparse_result.columns:\n",
    "        try:\n",
    "            count = sparse_result[col].sum()\n",
    "            if count < cut_below and \"linguistics\" in col:\n",
    "                to_drop.append(col)\n",
    "        except Exception:\n",
    "            continue\n",
    "    return sparse_result.drop(columns=to_drop)\n",
    "\n",
    "def get_second_representation() -> pd.DataFrame:\n",
    "    data = []\n",
    "    col_names = [f\"BERTweet_{i}\" for i in range(768)]\n",
    "    for idx in DF_TRAIN.index:\n",
    "        tweet = ' '.join([w.lemma_.lower() for w in nlp(DF_TRAIN.loc[idx][\"text\"]) if not w.is_stop])\n",
    "        input_ids = torch.tensor([tokenizer.encode(tweet)])\n",
    "        with torch.no_grad():\n",
    "            outputs = bertweet(input_ids)\n",
    "            hidden_states = outputs[0]\n",
    "        token_embeddings = np.array([ll.numpy() for ll in hidden_states[0]])\n",
    "        sentence_embedding = np.mean(token_embeddings, axis=0)\n",
    "        o = {\"id\": idx}\n",
    "        o = {**o, **dict(zip(col_names, sentence_embedding))}\n",
    "        data.append(o)\n",
    "    return pd.DataFrame(data).set_index(\"id\").fillna(0)\n",
    "\n",
    "def get_third_representation() -> pd.DataFrame:\n",
    "    attributes = []\n",
    "    for idx in DF_TRAIN.index:\n",
    "        tweet = DF_TRAIN.loc[idx][\"text\"]\n",
    "        o = {\"id\": idx}\n",
    "        o = {**o, **get_lexicon_attrib(tweet)}\n",
    "        attributes.append(o)\n",
    "    return pd.DataFrame(attributes).set_index(\"id\").fillna(0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "outputs": [],
   "source": [
    "pickle.dump(get_first_representation(), open(\"revision/df_representation_v1.pickle\", \"wb\"))\n",
    "pickle.dump(get_second_representation(), open(\"revision/df_representation_v2.pickle\", \"wb\"))\n",
    "pickle.dump(get_third_representation(), open(\"revision/df_representation_v3.pickle\", \"wb\"))\n",
    "\n",
    "df_representation_v4 = pd.concat([\n",
    "    pickle.load(open(\"revision/df_representation_v3.pickle\", \"rb\")),\n",
    "    pickle.load(open(\"revision/df_representation_v1.pickle\", \"rb\"))\n",
    "], axis=1)\n",
    "pickle.dump(df_representation_v4, open(\"revision/df_representation_v4.pickle\", \"wb\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Seleccionar columnas"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "outputs": [],
   "source": [
    "def get_best_f1(df: pd.DataFrame, indexes, ranked_cols, skip) -> int:\n",
    "    f1_weight = []\n",
    "    for num_cols in range(1, len(ranked_cols) + 1, skip):\n",
    "        x = df.loc[indexes][ranked_cols[:num_cols+1]]\n",
    "        y = DF_TRAIN.loc[x.index][\"int\"]\n",
    "        clf = make_pipeline(StandardScaler(), SVC(kernel=\"rbf\", gamma='auto', class_weight=\"balanced\"))\n",
    "        cv_results = cross_validate(clf, x, y, cv=5, scoring=\"f1_weighted\")\n",
    "        test_score = cv_results[\"test_score\"]\n",
    "        f1_weight.append([num_cols, np.mean(test_score), np.std(test_score)])\n",
    "    return sorted(f1_weight, key=lambda i: i[1], reverse=True)[0][0]\n",
    "\n",
    "\n",
    "def get_fine_best_f1(df: pd.DataFrame, indexes, ranked_cols, skip) -> int:\n",
    "    best_f1 = get_best_f1(df, indexes, ranked_cols, skip)\n",
    "    fine_f1_weight = []\n",
    "    for num_cols in range(best_f1 - skip, best_f1 + skip, 1):\n",
    "        x = df.loc[indexes][ranked_cols[:num_cols + 1]]\n",
    "        y = DF_TRAIN.loc[x.index][\"int\"]\n",
    "        clf = make_pipeline(StandardScaler(), SVC(kernel=\"rbf\", gamma='auto', class_weight=\"balanced\"))\n",
    "        cv_results = cross_validate(clf, x, y, cv=5, scoring=\"f1_weighted\")\n",
    "        test_score = cv_results[\"test_score\"]\n",
    "        fine_f1_weight.append([num_cols, np.mean(test_score), np.std(test_score)])\n",
    "    return sorted(fine_f1_weight, key=lambda i: i[1], reverse=True)[0][0]\n",
    "\n",
    "\n",
    "def get_indexes_and_ranked_cols(df: pd.DataFrame, sen: str):\n",
    "    indexes = DF_TRAIN[DF_TRAIN[\"sen\"] == sen].index\n",
    "    indexes_lh = DF_TRAIN.loc[indexes][DF_TRAIN.loc[indexes][\"int\"].isin([\"low\", \"high\"])].index\n",
    "\n",
    "    x = df.loc[indexes_lh]\n",
    "    y = DF_TRAIN.loc[x.index][\"int\"]\n",
    "\n",
    "    dic_label_count = y.value_counts().to_dict()\n",
    "    min_label = min(dic_label_count.items(), key=lambda i: i[1])[0]\n",
    "    max_label = max(dic_label_count.items(), key=lambda i: i[1])[0]\n",
    "    index_label_1 = y[y==min_label].index\n",
    "    oversampling_steps = int(dic_label_count[max_label] / dic_label_count[min_label]) - 1\n",
    "    x_res, y_res = x.copy(), y.copy()\n",
    "\n",
    "    for step in range(oversampling_steps):\n",
    "        new_indexes = [f\"{idx}+{step + 1}\" for idx in index_label_1]\n",
    "        copied_sub_x = pd.DataFrame(x.loc[index_label_1].values, columns=x.columns, index=new_indexes)\n",
    "        copied_sub_y = pd.Series(y.loc[index_label_1].values, index=new_indexes)\n",
    "        x_res = pd.concat([x_res, copied_sub_x], axis=0)\n",
    "        y_res = pd.concat([y_res, copied_sub_y], axis=0)\n",
    "\n",
    "    x_res = pd.DataFrame(StandardScaler().fit_transform(x_res), columns=x_res.columns, index=x_res.index)\n",
    "    selector = SelectKBest(chi2, k=x.shape[1])\n",
    "    x_res_ = x_res - x_res.min()\n",
    "    selector.fit(x_res_, y_res)\n",
    "    scores_selector = {col: selector.scores_[i] if str(selector.scores_[i]) != \"nan\" else 0 for i, col in enumerate(x.columns.tolist())}\n",
    "    ranked_cols = [x[0] for x in sorted(scores_selector.items(), key=lambda i: i[1], reverse=True)]\n",
    "    return indexes, ranked_cols\n",
    "\n",
    "\n",
    "def dump_cols_selected(df: pd.DataFrame, version: int, skip=10) -> None:\n",
    "    for sen in SENTIMENTS:\n",
    "        indexes, ranked_cols = get_indexes_and_ranked_cols(df, sen)\n",
    "        pickle.dump(ranked_cols[:get_fine_best_f1(df, indexes, ranked_cols, skip) + 1], open(f\"revision/cols_selected_{sen}_v{version}.pickle\", \"wb\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "outputs": [],
   "source": [
    "dump_cols_selected(pickle.load(open(\"revision/df_representation_v1.pickle\", \"rb\")), 1)\n",
    "dump_cols_selected(pickle.load(open(\"revision/df_representation_v2.pickle\", \"rb\")), 2)\n",
    "dump_cols_selected(pickle.load(open(\"revision/df_representation_v3.pickle\", \"rb\")), 3, 1)\n",
    "dump_cols_selected(pickle.load(open(\"revision/df_representation_v4.pickle\", \"rb\")), 4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluación"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "outputs": [],
   "source": [
    "METRICS = \"auc kappa accuracy\".split()\n",
    "N_FITS = 100\n",
    "\n",
    "summary_baseline = pd.DataFrame({\n",
    "    \"sen\": SENTIMENTS,\n",
    "    \"auc\": [0.62, 0.67, 0.65, 0.67],\n",
    "    \"kappa\": [0.07, 0.15, 0.18, 0.19],\n",
    "    \"accuracy\": [0.63, 0.57, 0.54, 0.55]\n",
    "}).set_index(\"sen\")\n",
    "\n",
    "df_representation_v1 = pickle.load(open(\"revision/df_representation_v1.pickle\", \"rb\"))\n",
    "df_representation_v2 = pickle.load(open(\"revision/df_representation_v2.pickle\", \"rb\"))\n",
    "df_representation_v3 = pickle.load(open(\"revision/df_representation_v3.pickle\", \"rb\"))\n",
    "df_representation_v4 = pickle.load(open(\"revision/df_representation_v4.pickle\", \"rb\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "outputs": [],
   "source": [
    "def auc_score(test_set, predicted_set) -> float:\n",
    "    high_predicted = np.array([prediction[2] for prediction in predicted_set])\n",
    "    medium_predicted = np.array([prediction[1] for prediction in predicted_set])\n",
    "    low_predicted = np.array([prediction[0] for prediction in predicted_set])\n",
    "    high_test = np.where(test_set == 'high', 1.0, 0.0)\n",
    "    medium_test = np.where(test_set == 'medium', 1.0, 0.0)\n",
    "    low_test = np.where(test_set == 'low', 1.0, 0.0)\n",
    "    auc_high = roc_auc_score(high_test, high_predicted)\n",
    "    auc_med = roc_auc_score(medium_test, medium_predicted)\n",
    "    auc_low = roc_auc_score(low_test, low_predicted)\n",
    "    auc_w = (low_test.sum() * auc_low + medium_test.sum() * auc_med +\n",
    "             high_test.sum() * auc_high) / (\n",
    "                 low_test.sum() + medium_test.sum() + high_test.sum())\n",
    "    return auc_w"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "outputs": [],
   "source": [
    "def get_summary(df: pd.DataFrame, version: int) -> dict:\n",
    "    summary = {sen: {l: [] for l in METRICS} for sen in SENTIMENTS}\n",
    "    for sen in SENTIMENTS:\n",
    "        for _ in range(N_FITS):\n",
    "            indexes = DF_TRAIN[DF_TRAIN[\"sen\"] == sen].index\n",
    "            cols_selected_sen = pickle.load(open(f\"revision/cols_selected_{sen}_v{version}.pickle\", \"rb\"))\n",
    "\n",
    "            x = df.loc[indexes][cols_selected_sen]\n",
    "            y = DF_TRAIN.loc[x.index][\"int\"]\n",
    "\n",
    "            x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=np.random.randint(1, x.shape[0]))\n",
    "            y_train = y_train.replace({\"low\": 0, \"medium\": 1, \"high\": 2})\n",
    "            clf = make_pipeline(StandardScaler(), SVC(gamma='auto', class_weight=\"balanced\", probability=True))\n",
    "            clf.fit(x_train, y_train)\n",
    "            clf.score(x_test, y_test.replace({\"low\": 0, \"medium\": 1, \"high\": 2}))\n",
    "            y_pred = clf.predict_proba(x_test)\n",
    "            predicted_labels = [\n",
    "                INTENSITIES[np.argmax(item)] for item in y_pred\n",
    "            ]\n",
    "\n",
    "            auc = round(auc_score(y_test, y_pred), 3)\n",
    "            kappa = round(cohen_kappa_score(y_test, predicted_labels), 3)\n",
    "            accuracy = round(accuracy_score(y_test, predicted_labels), 3)\n",
    "            summary[sen][\"auc\"].append(auc)\n",
    "            summary[sen][\"kappa\"].append(kappa)\n",
    "            summary[sen][\"accuracy\"].append(accuracy)\n",
    "    return summary\n",
    "\n",
    "\n",
    "def get_evaluation(filename: str) -> pd.DataFrame:\n",
    "    return pd.DataFrame({l: {sen: round(np.mean(pickle.load(open(filename, \"rb\"))[sen][l]), 3) for sen in SENTIMENTS} for l in METRICS})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "outputs": [],
   "source": [
    "pickle.dump(get_summary(df_representation_v1, 1), open(\"revision/summary_v1.pickle\", \"wb\"))\n",
    "pickle.dump(get_summary(df_representation_v2, 2), open(\"revision/summary_v2.pickle\", \"wb\"))\n",
    "pickle.dump(get_summary(df_representation_v3, 3), open(\"revision/summary_v3.pickle\", \"wb\"))\n",
    "pickle.dump(get_summary(df_representation_v4, 4), open(\"revision/summary_v4.pickle\", \"wb\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "           auc  kappa  accuracy\nanger    0.721  0.282     0.680\nfear     0.751  0.366     0.648\njoy      0.785  0.409     0.659\nsadness  0.717  0.286     0.590",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>auc</th>\n      <th>kappa</th>\n      <th>accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>anger</th>\n      <td>0.721</td>\n      <td>0.282</td>\n      <td>0.680</td>\n    </tr>\n    <tr>\n      <th>fear</th>\n      <td>0.751</td>\n      <td>0.366</td>\n      <td>0.648</td>\n    </tr>\n    <tr>\n      <th>joy</th>\n      <td>0.785</td>\n      <td>0.409</td>\n      <td>0.659</td>\n    </tr>\n    <tr>\n      <th>sadness</th>\n      <td>0.717</td>\n      <td>0.286</td>\n      <td>0.590</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_evaluation(\"summary_v1.pickle\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "           auc  kappa  accuracy\nanger    0.764  0.309     0.698\nfear     0.775  0.369     0.653\njoy      0.796  0.427     0.673\nsadness  0.779  0.376     0.639",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>auc</th>\n      <th>kappa</th>\n      <th>accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>anger</th>\n      <td>0.764</td>\n      <td>0.309</td>\n      <td>0.698</td>\n    </tr>\n    <tr>\n      <th>fear</th>\n      <td>0.775</td>\n      <td>0.369</td>\n      <td>0.653</td>\n    </tr>\n    <tr>\n      <th>joy</th>\n      <td>0.796</td>\n      <td>0.427</td>\n      <td>0.673</td>\n    </tr>\n    <tr>\n      <th>sadness</th>\n      <td>0.779</td>\n      <td>0.376</td>\n      <td>0.639</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_evaluation(\"summary_v2.pickle\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "outputs": [
    {
     "data": {
      "text/plain": "           auc  kappa  accuracy\nanger    0.713  0.152     0.654\nfear     0.703  0.306     0.618\njoy      0.764  0.367     0.635\nsadness  0.725  0.304     0.596",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>auc</th>\n      <th>kappa</th>\n      <th>accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>anger</th>\n      <td>0.713</td>\n      <td>0.152</td>\n      <td>0.654</td>\n    </tr>\n    <tr>\n      <th>fear</th>\n      <td>0.703</td>\n      <td>0.306</td>\n      <td>0.618</td>\n    </tr>\n    <tr>\n      <th>joy</th>\n      <td>0.764</td>\n      <td>0.367</td>\n      <td>0.635</td>\n    </tr>\n    <tr>\n      <th>sadness</th>\n      <td>0.725</td>\n      <td>0.304</td>\n      <td>0.596</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_evaluation(\"revision/summary_v1.pickle\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "outputs": [
    {
     "data": {
      "text/plain": "           auc  kappa  accuracy\nanger    0.747  0.286     0.695\nfear     0.753  0.338     0.641\njoy      0.763  0.347     0.634\nsadness  0.738  0.296     0.603",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>auc</th>\n      <th>kappa</th>\n      <th>accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>anger</th>\n      <td>0.747</td>\n      <td>0.286</td>\n      <td>0.695</td>\n    </tr>\n    <tr>\n      <th>fear</th>\n      <td>0.753</td>\n      <td>0.338</td>\n      <td>0.641</td>\n    </tr>\n    <tr>\n      <th>joy</th>\n      <td>0.763</td>\n      <td>0.347</td>\n      <td>0.634</td>\n    </tr>\n    <tr>\n      <th>sadness</th>\n      <td>0.738</td>\n      <td>0.296</td>\n      <td>0.603</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_evaluation(\"revision/summary_v2.pickle\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [
    {
     "data": {
      "text/plain": "          auc  kappa  accuracy\nsen                           \nanger    0.62   0.07      0.63\nfear     0.67   0.15      0.57\njoy      0.65   0.18      0.54\nsadness  0.67   0.19      0.55",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>auc</th>\n      <th>kappa</th>\n      <th>accuracy</th>\n    </tr>\n    <tr>\n      <th>sen</th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>anger</th>\n      <td>0.62</td>\n      <td>0.07</td>\n      <td>0.63</td>\n    </tr>\n    <tr>\n      <th>fear</th>\n      <td>0.67</td>\n      <td>0.15</td>\n      <td>0.57</td>\n    </tr>\n    <tr>\n      <th>joy</th>\n      <td>0.65</td>\n      <td>0.18</td>\n      <td>0.54</td>\n    </tr>\n    <tr>\n      <th>sadness</th>\n      <td>0.67</td>\n      <td>0.19</td>\n      <td>0.55</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_baseline"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "outputs": [
    {
     "data": {
      "text/plain": "           auc  kappa  accuracy\nanger    0.569  0.000     0.657\nfear     0.598  0.009     0.558\njoy      0.592  0.020     0.528\nsadness  0.584  0.001     0.521",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>auc</th>\n      <th>kappa</th>\n      <th>accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>anger</th>\n      <td>0.569</td>\n      <td>0.000</td>\n      <td>0.657</td>\n    </tr>\n    <tr>\n      <th>fear</th>\n      <td>0.598</td>\n      <td>0.009</td>\n      <td>0.558</td>\n    </tr>\n    <tr>\n      <th>joy</th>\n      <td>0.592</td>\n      <td>0.020</td>\n      <td>0.528</td>\n    </tr>\n    <tr>\n      <th>sadness</th>\n      <td>0.584</td>\n      <td>0.001</td>\n      <td>0.521</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_evaluation(\"revision/summary_v3.pickle\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "outputs": [
    {
     "data": {
      "text/plain": "           auc  kappa  accuracy\nanger    0.630  0.093     0.650\nfear     0.715  0.288     0.616\njoy      0.767  0.369     0.635\nsadness  0.713  0.294     0.597",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>auc</th>\n      <th>kappa</th>\n      <th>accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>anger</th>\n      <td>0.630</td>\n      <td>0.093</td>\n      <td>0.650</td>\n    </tr>\n    <tr>\n      <th>fear</th>\n      <td>0.715</td>\n      <td>0.288</td>\n      <td>0.616</td>\n    </tr>\n    <tr>\n      <th>joy</th>\n      <td>0.767</td>\n      <td>0.369</td>\n      <td>0.635</td>\n    </tr>\n    <tr>\n      <th>sadness</th>\n      <td>0.713</td>\n      <td>0.294</td>\n      <td>0.597</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_evaluation(\"revision/summary_v4.pickle\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}