{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1042f194",
   "metadata": {},
   "source": [
    "**NLP**\n",
    "\n",
    "*CC6205-1 - Oto√±o 2022*\n",
    "\n",
    "Autor: Felipe Urrutia Vargas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "61754f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade pandas\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# pd.set_option(\"max_rows\", None)\n",
    "import pickle\n",
    "from string import punctuation\n",
    "import re\n",
    "\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# from astropy.visualization import hist\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.rc('axes', titlesize=14)\n",
    "plt.rc('legend', fontsize=14)\n",
    "plt.rc('xtick', labelsize=12)\n",
    "plt.rc('ytick', labelsize=12)\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "plt.rcParams['axes.titlesize'] = 16\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 6)\n",
    "plt.rcParams.update({'lines.markeredgewidth': 1})\n",
    "plt.rcParams.update({'errorbar.capsize': 2})\n",
    "import random\n",
    "\n",
    "import plotly.express as px\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.metrics import confusion_matrix, cohen_kappa_score, classification_report, accuracy_score, roc_auc_score\n",
    "from sklearn.base import BaseEstimator, TransformerMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94b37680",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiments = \"anger fear joy sadness\".split()\n",
    "intensities = \"low medium high\".split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "03e4b431",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_baseline = pd.DataFrame({\n",
    "    \"sen\": sentiments,\n",
    "    \"auc\": [0.62, 0.67, 0.65, 0.67],\n",
    "    \"kappa\": [0.07, 0.15, 0.18, 0.19],\n",
    "    \"accuracy\": [0.63, 0.57, 0.54, 0.55] \n",
    "             }).set_index(\"sen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ef94e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pickle.load(open(\"df_train.pickle\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ea2a127",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_representation = pickle.load(open(\"df_representation_v1.pickle\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f8701a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "partition_attrib = {\n",
    "    type_attrib: [c for c in df_representation.columns if type_attrib+\"<&>\" in c]\n",
    "    for type_attrib in \"retro punct emoji linguistics\".split()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47f50444",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('summary type attrib',\n",
       " {'retro': 13, 'punct': 7, 'emoji': 190, 'linguistics': 11540})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"summary type attrib\", {k: len(v) for k, v in partition_attrib.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "92caee50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def auc_score(test_set, predicted_set):\n",
    "    high_predicted = np.array([prediction[2] for prediction in predicted_set])\n",
    "    medium_predicted = np.array([prediction[1] for prediction in predicted_set])\n",
    "    low_predicted = np.array([prediction[0] for prediction in predicted_set])\n",
    "    high_test = np.where(test_set == 'high', 1.0, 0.0)\n",
    "    medium_test = np.where(test_set == 'medium', 1.0, 0.0)\n",
    "    low_test = np.where(test_set == 'low', 1.0, 0.0)\n",
    "    auc_high = roc_auc_score(high_test, high_predicted)\n",
    "    auc_med = roc_auc_score(medium_test, medium_predicted)\n",
    "    auc_low = roc_auc_score(low_test, low_predicted)\n",
    "    auc_w = (low_test.sum() * auc_low + medium_test.sum() * auc_med +\n",
    "             high_test.sum() * auc_high) / (\n",
    "                 low_test.sum() + medium_test.sum() + high_test.sum())\n",
    "    return auc_w\n",
    "\n",
    "\n",
    "def evaulate(predicted_probabilities, y_test, labels, dataset_name):\n",
    "    # Importante: al transformar los arreglos de probabilidad a clases,\n",
    "    # entregar el arreglo de clases aprendido por el clasificador.\n",
    "    # (que comunmente, es distinto a ['low', 'medium', 'high'])\n",
    "    predicted_labels = [\n",
    "        labels[np.argmax(item)] for item in predicted_probabilities\n",
    "    ]\n",
    "    print('Confusion Matrix for {}:\\n'.format(dataset_name))\n",
    "    print(\n",
    "        confusion_matrix(y_test,\n",
    "                         predicted_labels,\n",
    "                         labels=['low', 'medium', 'high']))\n",
    "\n",
    "    print('\\nClassification Report:\\n')\n",
    "    print(\n",
    "        classification_report(y_test,\n",
    "                              predicted_labels,\n",
    "                              labels=['low', 'medium', 'high']))\n",
    "    # Reorder predicted probabilities array.\n",
    "    labels = labels.tolist()\n",
    "    predicted_probabilities = predicted_probabilities[:, [\n",
    "        labels.index('low'),\n",
    "        labels.index('medium'),\n",
    "        labels.index('high')\n",
    "    ]]\n",
    "    auc = round(auc_score(y_test, predicted_probabilities), 3)\n",
    "    print(\"Scores:\\n\\nAUC: \", auc, end='\\t')\n",
    "    kappa = round(cohen_kappa_score(y_test, predicted_labels), 3)\n",
    "    print(\"Kappa:\", kappa, end='\\t')\n",
    "    accuracy = round(accuracy_score(y_test, predicted_labels), 3)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print('------------------------------------------------------\\n')\n",
    "    return np.array([auc, kappa, accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01b3842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[anger] Scores:\n",
      " AUC:  0.738\tKappa: 0.316\tAccuracy: 0.698\n",
      "\n",
      "[anger] Scores:\n",
      " AUC:  0.769\tKappa: 0.254\tAccuracy: 0.693\n",
      "\n",
      "[anger] Scores:\n",
      " AUC:  0.721\tKappa: 0.249\tAccuracy: 0.646\n",
      "\n",
      "[anger] Scores:\n",
      " AUC:  0.706\tKappa: 0.335\tAccuracy: 0.73\n",
      "\n",
      "[anger] Scores:\n",
      " AUC:  0.686\tKappa: 0.3\tAccuracy: 0.677\n",
      "\n",
      "[anger] Scores:\n",
      " AUC:  0.77\tKappa: 0.343\tAccuracy: 0.73\n",
      "\n",
      "[anger] Scores:\n",
      " AUC:  0.728\tKappa: 0.302\tAccuracy: 0.677\n",
      "\n",
      "[anger] Scores:\n",
      " AUC:  0.757\tKappa: 0.29\tAccuracy: 0.677\n",
      "\n",
      "[anger] Scores:\n",
      " AUC:  0.757\tKappa: 0.304\tAccuracy: 0.698\n",
      "\n",
      "[anger] Scores:\n",
      " AUC:  0.73\tKappa: 0.213\tAccuracy: 0.624\n",
      "\n",
      "[anger] Scores:\n",
      " AUC:  0.691\tKappa: 0.25\tAccuracy: 0.688\n",
      "\n",
      "[anger] Scores:\n",
      " AUC:  0.75\tKappa: 0.255\tAccuracy: 0.677\n",
      "\n",
      "[anger] Scores:\n",
      " AUC:  0.703\tKappa: 0.33\tAccuracy: 0.698\n",
      "\n",
      "[anger] Scores:\n",
      " AUC:  0.706\tKappa: 0.233\tAccuracy: 0.635\n",
      "\n",
      "[anger] Scores:\n",
      " AUC:  0.765\tKappa: 0.391\tAccuracy: 0.704\n",
      "\n",
      "[anger] Scores:\n",
      " AUC:  0.758\tKappa: 0.36\tAccuracy: 0.688\n",
      "\n",
      "[anger] Scores:\n",
      " AUC:  0.743\tKappa: 0.315\tAccuracy: 0.704\n",
      "\n",
      "[anger] Scores:\n",
      " AUC:  0.744\tKappa: 0.218\tAccuracy: 0.646\n",
      "\n",
      "[anger] Scores:\n",
      " AUC:  0.671\tKappa: 0.169\tAccuracy: 0.64\n",
      "\n",
      "[anger] Scores:\n",
      " AUC:  0.746\tKappa: 0.313\tAccuracy: 0.693\n",
      "\n",
      "[anger] Scores:\n",
      " AUC:  0.77\tKappa: 0.281\tAccuracy: 0.677\n",
      "\n",
      "[anger] Scores:\n",
      " AUC:  0.762\tKappa: 0.322\tAccuracy: 0.672\n",
      "\n",
      "[anger] Scores:\n",
      " AUC:  0.738\tKappa: 0.307\tAccuracy: 0.688\n",
      "\n",
      "[anger] Scores:\n",
      " AUC:  0.77\tKappa: 0.324\tAccuracy: 0.688\n",
      "\n",
      "[anger] Scores:\n",
      " AUC:  0.663\tKappa: 0.205\tAccuracy: 0.667\n",
      "\n",
      "[anger] Scores:\n",
      " AUC:  0.729\tKappa: 0.337\tAccuracy: 0.72\n",
      "\n",
      "[anger] Scores:\n",
      " AUC:  0.703\tKappa: 0.201\tAccuracy: 0.646\n",
      "\n",
      "[anger] Scores:\n",
      " AUC:  0.75\tKappa: 0.283\tAccuracy: 0.672\n",
      "\n",
      "[anger] Scores:\n",
      " AUC:  0.763\tKappa: 0.328\tAccuracy: 0.698\n",
      "\n",
      "[anger] Scores:\n",
      " AUC:  0.734\tKappa: 0.254\tAccuracy: 0.651\n",
      "\n",
      "[anger] Scores:\n",
      " AUC:  0.688\tKappa: 0.222\tAccuracy: 0.646\n",
      "\n",
      "[anger] Scores:\n",
      " AUC:  0.704\tKappa: 0.24\tAccuracy: 0.646\n",
      "\n",
      "[anger] Scores:\n",
      " AUC:  0.708\tKappa: 0.294\tAccuracy: 0.672\n",
      "\n",
      "[anger] Scores:\n",
      " AUC:  0.72\tKappa: 0.267\tAccuracy: 0.656\n",
      "\n",
      "[anger] Scores:\n",
      " AUC:  0.77\tKappa: 0.382\tAccuracy: 0.72\n",
      "\n",
      "[anger] Scores:\n",
      " AUC:  0.724\tKappa: 0.313\tAccuracy: 0.683\n",
      "\n",
      "[anger] Scores:\n",
      " AUC:  0.702\tKappa: 0.201\tAccuracy: 0.608\n",
      "\n",
      "[anger] Scores:\n",
      " AUC:  0.749\tKappa: 0.331\tAccuracy: 0.698\n",
      "\n",
      "[anger] Scores:\n",
      " AUC:  0.733\tKappa: 0.26\tAccuracy: 0.656\n",
      "\n",
      "[anger] Scores:\n",
      " AUC:  0.708\tKappa: 0.22\tAccuracy: 0.661\n",
      "\n",
      "[anger] Scores:\n",
      " AUC:  0.678\tKappa: 0.277\tAccuracy: 0.698\n",
      "\n",
      "[anger] Scores:\n",
      " AUC:  0.779\tKappa: 0.308\tAccuracy: 0.688\n",
      "\n",
      "[anger] Scores:\n",
      " AUC:  0.673\tKappa: 0.164\tAccuracy: 0.608\n",
      "\n",
      "[anger] Scores:\n",
      " AUC:  0.731\tKappa: 0.277\tAccuracy: 0.677\n",
      "\n",
      "[anger] Scores:\n",
      " AUC:  0.695\tKappa: 0.159\tAccuracy: 0.608\n",
      "\n",
      "[anger] Scores:\n",
      " AUC:  0.735\tKappa: 0.324\tAccuracy: 0.677\n",
      "\n",
      "[anger] Scores:\n",
      " AUC:  0.719\tKappa: 0.228\tAccuracy: 0.667\n",
      "\n",
      "[anger] Scores:\n",
      " AUC:  0.735\tKappa: 0.367\tAccuracy: 0.683\n",
      "\n",
      "[anger] Scores:\n",
      " AUC:  0.765\tKappa: 0.284\tAccuracy: 0.683\n",
      "\n",
      "[anger] Scores:\n",
      " AUC:  0.758\tKappa: 0.352\tAccuracy: 0.709\n",
      "\n",
      "[anger] Scores:\n",
      " AUC:  0.716\tKappa: 0.319\tAccuracy: 0.709\n",
      "\n",
      "[anger] Scores:\n",
      " AUC:  0.712\tKappa: 0.338\tAccuracy: 0.704\n",
      "\n",
      "[anger] Scores:\n",
      " AUC:  0.731\tKappa: 0.247\tAccuracy: 0.677\n",
      "\n",
      "[anger] Scores:\n",
      " AUC:  0.756\tKappa: 0.284\tAccuracy: 0.688\n",
      "\n",
      "[anger] Scores:\n",
      " AUC:  0.749\tKappa: 0.254\tAccuracy: 0.646\n",
      "\n",
      "[anger] Scores:\n",
      " AUC:  0.77\tKappa: 0.263\tAccuracy: 0.667\n",
      "\n",
      "[anger] Scores:\n",
      " AUC:  0.747\tKappa: 0.349\tAccuracy: 0.73\n",
      "\n",
      "[anger] Scores:\n",
      " AUC:  0.767\tKappa: 0.303\tAccuracy: 0.698\n",
      "\n",
      "[anger] Scores:\n",
      " AUC:  0.674\tKappa: 0.182\tAccuracy: 0.624\n",
      "\n",
      "[anger] Scores:\n",
      " AUC:  0.765\tKappa: 0.279\tAccuracy: 0.693\n",
      "\n",
      "[anger] Scores:\n",
      " AUC:  0.782\tKappa: 0.25\tAccuracy: 0.693\n",
      "\n",
      "[anger] Scores:\n",
      " AUC:  0.707\tKappa: 0.193\tAccuracy: 0.651\n",
      "\n",
      "[anger] Scores:\n",
      " AUC:  0.709\tKappa: 0.242\tAccuracy: 0.672\n",
      "\n",
      "[anger] Scores:\n",
      " AUC:  0.731\tKappa: 0.3\tAccuracy: 0.651\n",
      "\n",
      "[anger] Scores:\n",
      " AUC:  0.725\tKappa: 0.22\tAccuracy: 0.672\n",
      "\n",
      "[anger] Scores:\n",
      " AUC:  0.706\tKappa: 0.343\tAccuracy: 0.698\n",
      "\n",
      "[anger] Scores:\n",
      " AUC:  0.705\tKappa: 0.194\tAccuracy: 0.64\n",
      "\n",
      "[anger] Scores:\n",
      " AUC:  0.739\tKappa: 0.32\tAccuracy: 0.698\n",
      "\n",
      "[anger] Scores:\n",
      " AUC:  0.696\tKappa: 0.185\tAccuracy: 0.651\n",
      "\n",
      "[anger] Scores:\n",
      " AUC:  0.746\tKappa: 0.355\tAccuracy: 0.672\n",
      "\n",
      "[anger] Scores:\n",
      " AUC:  0.757\tKappa: 0.331\tAccuracy: 0.725\n",
      "\n",
      "[anger] Scores:\n",
      " AUC:  0.719\tKappa: 0.3\tAccuracy: 0.677\n",
      "\n",
      "[anger] Scores:\n",
      " AUC:  0.702\tKappa: 0.314\tAccuracy: 0.693\n",
      "\n",
      "[anger] Scores:\n",
      " AUC:  0.704\tKappa: 0.352\tAccuracy: 0.735\n",
      "\n",
      "[anger] Scores:\n",
      " AUC:  0.717\tKappa: 0.319\tAccuracy: 0.688\n",
      "\n",
      "[anger] Scores:\n",
      " AUC:  0.685\tKappa: 0.207\tAccuracy: 0.677\n",
      "\n",
      "[anger] Scores:\n",
      " AUC:  0.705\tKappa: 0.33\tAccuracy: 0.698\n",
      "\n",
      "[anger] Scores:\n",
      " AUC:  0.76\tKappa: 0.281\tAccuracy: 0.672\n",
      "\n",
      "[anger] Scores:\n",
      " AUC:  0.649\tKappa: 0.231\tAccuracy: 0.635\n",
      "\n",
      "[anger] Scores:\n",
      " AUC:  0.757\tKappa: 0.279\tAccuracy: 0.661\n",
      "\n",
      "[anger] Scores:\n",
      " AUC:  0.733\tKappa: 0.261\tAccuracy: 0.661\n",
      "\n",
      "[anger] Scores:\n",
      " AUC:  0.738\tKappa: 0.316\tAccuracy: 0.698\n",
      "\n",
      "[anger] Scores:\n",
      " AUC:  0.724\tKappa: 0.201\tAccuracy: 0.683\n",
      "\n",
      "[anger] Scores:\n",
      " AUC:  0.74\tKappa: 0.326\tAccuracy: 0.683\n",
      "\n",
      "[anger] Scores:\n",
      " AUC:  0.729\tKappa: 0.258\tAccuracy: 0.677\n",
      "\n",
      "[anger] Scores:\n",
      " AUC:  0.73\tKappa: 0.246\tAccuracy: 0.688\n",
      "\n",
      "[anger] Scores:\n",
      " AUC:  0.727\tKappa: 0.305\tAccuracy: 0.651\n",
      "\n",
      "[anger] Scores:\n",
      " AUC:  0.709\tKappa: 0.176\tAccuracy: 0.614\n",
      "\n",
      "[anger] Scores:\n",
      " AUC:  0.686\tKappa: 0.281\tAccuracy: 0.651\n",
      "\n",
      "[anger] Scores:\n",
      " AUC:  0.747\tKappa: 0.266\tAccuracy: 0.672\n",
      "\n",
      "[anger] Scores:\n",
      " AUC:  0.697\tKappa: 0.244\tAccuracy: 0.677\n",
      "\n",
      "[anger] Scores:\n",
      " AUC:  0.703\tKappa: 0.352\tAccuracy: 0.735\n",
      "\n",
      "[anger] Scores:\n",
      " AUC:  0.752\tKappa: 0.355\tAccuracy: 0.698\n",
      "\n",
      "[anger] Scores:\n",
      " AUC:  0.707\tKappa: 0.351\tAccuracy: 0.709\n",
      "\n",
      "[anger] Scores:\n",
      " AUC:  0.692\tKappa: 0.292\tAccuracy: 0.672\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metrics = \"auc kappa accuracy\".split()\n",
    "summary = {sen: {l: [] for l in metrics} for sen in sentiments}\n",
    "N_fits = 100\n",
    "for sen in sentiments:\n",
    "    for _ in range(N_fits):\n",
    "        indexs = df_train[df_train[\"sen\"] == sen].index\n",
    "        cols_selected_sen = pickle.load(open(f\"cols_selected_{sen}_v1.pickle\", \"rb\"))\n",
    "\n",
    "        X = df_representation.loc[indexs][cols_selected_sen]\n",
    "        y = df_train.loc[X.index][\"int\"]\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=np.random.randint(1, X.shape[0]))\n",
    "        y_train = y_train.replace({\"low\": 0, \"medium\": 1, \"high\": 2})\n",
    "        clf = make_pipeline(StandardScaler(), SVC(gamma='auto', class_weight=\"balanced\", probability=True))\n",
    "        clf.fit(X_train, y_train)\n",
    "        clf.score(X_test, y_test.replace({\"low\": 0, \"medium\": 1, \"high\": 2}))\n",
    "        y_pred = clf.predict_proba(X_test)\n",
    "        predicted_labels = [\n",
    "            intensities[np.argmax(item)] for item in y_pred\n",
    "        ]\n",
    "        auc = round(auc_score(y_test, y_pred), 3)\n",
    "        print(f\"[{sen}] Scores:\\n AUC: \", auc, end='\\t')\n",
    "        kappa = round(cohen_kappa_score(y_test, predicted_labels), 3)\n",
    "        print(f\"Kappa:\", kappa, end='\\t')\n",
    "        accuracy = round(accuracy_score(y_test, predicted_labels), 3)\n",
    "        print(f\"Accuracy:\", accuracy, end=\"\\n\\n\")\n",
    "        \n",
    "        summary[sen][\"auc\"].append(auc)\n",
    "        summary[sen][\"kappa\"].append(kappa)\n",
    "        summary[sen][\"accuracy\"].append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a783d045",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({sen: {l: round(np.mean(summary[sen][l]), 3) for l in metrics} for sen in sentiments}).set_index(\"sen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "6a1da768",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>auc</th>\n",
       "      <th>kappa</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sen</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>anger</th>\n",
       "      <td>0.62</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fear</th>\n",
       "      <td>0.67</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>joy</th>\n",
       "      <td>0.65</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sadness</th>\n",
       "      <td>0.67</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          auc  kappa  accuracy\n",
       "sen                           \n",
       "anger    0.62   0.07      0.63\n",
       "fear     0.67   0.15      0.57\n",
       "joy      0.65   0.18      0.54\n",
       "sadness  0.67   0.19      0.55"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_baseline"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
