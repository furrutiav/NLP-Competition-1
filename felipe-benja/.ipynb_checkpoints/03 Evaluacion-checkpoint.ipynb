{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1042f194",
   "metadata": {},
   "source": [
    "**NLP**\n",
    "\n",
    "*CC6205-1 - Oto√±o 2022*\n",
    "\n",
    "Autor: Felipe Urrutia Vargas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61754f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade pandas\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# pd.set_option(\"max_rows\", None)\n",
    "import pickle\n",
    "from string import punctuation\n",
    "import re\n",
    "\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# from astropy.visualization import hist\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.rc('axes', titlesize=14)\n",
    "plt.rc('legend', fontsize=14)\n",
    "plt.rc('xtick', labelsize=12)\n",
    "plt.rc('ytick', labelsize=12)\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "plt.rcParams['axes.titlesize'] = 16\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 6)\n",
    "plt.rcParams.update({'lines.markeredgewidth': 1})\n",
    "plt.rcParams.update({'errorbar.capsize': 2})\n",
    "import random\n",
    "\n",
    "import plotly.express as px\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.metrics import confusion_matrix, cohen_kappa_score, classification_report, accuracy_score, roc_auc_score\n",
    "from sklearn.base import BaseEstimator, TransformerMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94b37680",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiments = \"anger fear joy sadness\".split()\n",
    "intensities = \"low medium high\".split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c9f324d",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_baseline = pd.DataFrame({\n",
    "    \"sen\": sentiments,\n",
    "    \"auc\": [0.62, 0.67, 0.65, 0.67],\n",
    "    \"kappa\": [0.07, 0.15, 0.18, 0.19],\n",
    "    \"accuracy\": [0.63, 0.57, 0.54, 0.55] \n",
    "             }).set_index(\"sen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ef94e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pickle.load(open(\"df_train.pickle\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea2a127",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_representation = pickle.load(open(\"df_representation_v1.pickle\", \"rb\"))\n",
    "df_representation_v2 = pickle.load(open(\"df_representation_v2.pickle\", \"rb\"))\n",
    "df_representation_v3 = pickle.load(open(\"df_representation_v3.pickle\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f8701a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "partition_attrib = {\n",
    "    type_attrib: [c for c in df_representation.columns if type_attrib+\"<&>\" in c]\n",
    "    for type_attrib in \"retro punct emoji linguistics\".split()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47f50444",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('summary type attrib',\n",
       " {'retro': 13, 'punct': 7, 'emoji': 190, 'linguistics': 11540})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"summary type attrib\", {k: len(v) for k, v in partition_attrib.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "92caee50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def auc_score(test_set, predicted_set):\n",
    "    high_predicted = np.array([prediction[2] for prediction in predicted_set])\n",
    "    medium_predicted = np.array([prediction[1] for prediction in predicted_set])\n",
    "    low_predicted = np.array([prediction[0] for prediction in predicted_set])\n",
    "    high_test = np.where(test_set == 'high', 1.0, 0.0)\n",
    "    medium_test = np.where(test_set == 'medium', 1.0, 0.0)\n",
    "    low_test = np.where(test_set == 'low', 1.0, 0.0)\n",
    "    auc_high = roc_auc_score(high_test, high_predicted)\n",
    "    auc_med = roc_auc_score(medium_test, medium_predicted)\n",
    "    auc_low = roc_auc_score(low_test, low_predicted)\n",
    "    auc_w = (low_test.sum() * auc_low + medium_test.sum() * auc_med +\n",
    "             high_test.sum() * auc_high) / (\n",
    "                 low_test.sum() + medium_test.sum() + high_test.sum())\n",
    "    return auc_w\n",
    "\n",
    "\n",
    "def evaulate(predicted_probabilities, y_test, labels, dataset_name):\n",
    "    # Importante: al transformar los arreglos de probabilidad a clases,\n",
    "    # entregar el arreglo de clases aprendido por el clasificador.\n",
    "    # (que comunmente, es distinto a ['low', 'medium', 'high'])\n",
    "    predicted_labels = [\n",
    "        labels[np.argmax(item)] for item in predicted_probabilities\n",
    "    ]\n",
    "    print('Confusion Matrix for {}:\\n'.format(dataset_name))\n",
    "    print(\n",
    "        confusion_matrix(y_test,\n",
    "                         predicted_labels,\n",
    "                         labels=['low', 'medium', 'high']))\n",
    "\n",
    "    print('\\nClassification Report:\\n')\n",
    "    print(\n",
    "        classification_report(y_test,\n",
    "                              predicted_labels,\n",
    "                              labels=['low', 'medium', 'high']))\n",
    "    # Reorder predicted probabilities array.\n",
    "    labels = labels.tolist()\n",
    "    predicted_probabilities = predicted_probabilities[:, [\n",
    "        labels.index('low'),\n",
    "        labels.index('medium'),\n",
    "        labels.index('high')\n",
    "    ]]\n",
    "    auc = round(auc_score(y_test, predicted_probabilities), 3)\n",
    "    print(\"Scores:\\n\\nAUC: \", auc, end='\\t')\n",
    "    kappa = round(cohen_kappa_score(y_test, predicted_labels), 3)\n",
    "    print(\"Kappa:\", kappa, end='\\t')\n",
    "    accuracy = round(accuracy_score(y_test, predicted_labels), 3)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print('------------------------------------------------------\\n')\n",
    "    return np.array([auc, kappa, accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b75dd04d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sentiments' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8408/2961357075.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"auc kappa accuracy\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0msummary\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0msen\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m}\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msen\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msentiments\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mN_fits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msen\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msentiments\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mN_fits\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sentiments' is not defined"
     ]
    }
   ],
   "source": [
    "metrics = \"auc kappa accuracy\".split()\n",
    "summary = {sen: {l: [] for l in metrics} for sen in sentiments}\n",
    "N_fits = 100\n",
    "for sen in sentiments:\n",
    "    for _ in range(N_fits):\n",
    "        indexs = df_train[df_train[\"sen\"] == sen].index\n",
    "        cols_selected_sen = pickle.load(open(f\"cols_selected_{sen}_v3.pickle\", \"rb\"))\n",
    "\n",
    "        X = df_representation_v3.loc[indexs][cols_selected_sen]\n",
    "        y = df_train.loc[X.index][\"int\"]\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=np.random.randint(1, X.shape[0]))\n",
    "        y_train = y_train.replace({\"low\": 0, \"medium\": 1, \"high\": 2})\n",
    "        clf = make_pipeline(StandardScaler(), SVC(gamma='auto', class_weight=\"balanced\", probability=True))\n",
    "        clf.fit(X_train, y_train)\n",
    "        clf.score(X_test, y_test.replace({\"low\": 0, \"medium\": 1, \"high\": 2}))\n",
    "        y_pred = clf.predict_proba(X_test)\n",
    "        predicted_labels = [\n",
    "            intensities[np.argmax(item)] for item in y_pred\n",
    "        ]\n",
    "        auc = round(auc_score(y_test, y_pred), 3)\n",
    "        print(f\"[{sen}] Scores:\\n AUC: \", auc, end='\\t')\n",
    "        kappa = round(cohen_kappa_score(y_test, predicted_labels), 3)\n",
    "        print(f\"Kappa:\", kappa, end='\\t')\n",
    "        accuracy = round(accuracy_score(y_test, predicted_labels), 3)\n",
    "        print(f\"Accuracy:\", accuracy, end=\"\\n\\n\")\n",
    "        \n",
    "        summary[sen][\"auc\"].append(auc)\n",
    "        summary[sen][\"kappa\"].append(kappa)\n",
    "        summary[sen][\"accuracy\"].append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "2f433c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(summary, open(\"summary_v3.pickle\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "090324d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>auc</th>\n",
       "      <th>kappa</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>anger</th>\n",
       "      <td>0.726</td>\n",
       "      <td>0.281</td>\n",
       "      <td>0.678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fear</th>\n",
       "      <td>0.751</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>joy</th>\n",
       "      <td>0.788</td>\n",
       "      <td>0.410</td>\n",
       "      <td>0.658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sadness</th>\n",
       "      <td>0.718</td>\n",
       "      <td>0.292</td>\n",
       "      <td>0.592</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           auc  kappa  accuracy\n",
       "anger    0.726  0.281     0.678\n",
       "fear     0.751  0.365     0.648\n",
       "joy      0.788  0.410     0.658\n",
       "sadness  0.718  0.292     0.592"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary = pickle.load(open(\"summary_v1.pickle\", \"rb\"))\n",
    "pd.DataFrame({l: {sen: round(np.mean(summary[sen][l]), 3) for sen in sentiments} for l in metrics})#.set_index(\"sen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "4ea3590f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>auc</th>\n",
       "      <th>kappa</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>anger</th>\n",
       "      <td>0.767</td>\n",
       "      <td>0.312</td>\n",
       "      <td>0.700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fear</th>\n",
       "      <td>0.781</td>\n",
       "      <td>0.371</td>\n",
       "      <td>0.652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>joy</th>\n",
       "      <td>0.802</td>\n",
       "      <td>0.432</td>\n",
       "      <td>0.674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sadness</th>\n",
       "      <td>0.770</td>\n",
       "      <td>0.357</td>\n",
       "      <td>0.631</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           auc  kappa  accuracy\n",
       "anger    0.767  0.312     0.700\n",
       "fear     0.781  0.371     0.652\n",
       "joy      0.802  0.432     0.674\n",
       "sadness  0.770  0.357     0.631"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary = pickle.load(open(\"summary_v2.pickle\", \"rb\"))\n",
    "pd.DataFrame({l: {sen: round(np.mean(summary[sen][l]), 3) for sen in sentiments} for l in metrics})#.set_index(\"sen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "995dad42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>auc</th>\n",
       "      <th>kappa</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>anger</th>\n",
       "      <td>0.747</td>\n",
       "      <td>0.309</td>\n",
       "      <td>0.684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fear</th>\n",
       "      <td>0.764</td>\n",
       "      <td>0.378</td>\n",
       "      <td>0.652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>joy</th>\n",
       "      <td>0.791</td>\n",
       "      <td>0.426</td>\n",
       "      <td>0.666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sadness</th>\n",
       "      <td>0.711</td>\n",
       "      <td>0.290</td>\n",
       "      <td>0.594</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           auc  kappa  accuracy\n",
       "anger    0.747  0.309     0.684\n",
       "fear     0.764  0.378     0.652\n",
       "joy      0.791  0.426     0.666\n",
       "sadness  0.711  0.290     0.594"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary = pickle.load(open(\"summary_v3.pickle\", \"rb\"))\n",
    "pd.DataFrame({l: {sen: round(np.mean(summary[sen][l]), 3) for sen in sentiments} for l in metrics})#.set_index(\"sen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e3f38095",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>auc</th>\n",
       "      <th>kappa</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sen</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>anger</th>\n",
       "      <td>0.62</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fear</th>\n",
       "      <td>0.67</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>joy</th>\n",
       "      <td>0.65</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sadness</th>\n",
       "      <td>0.67</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          auc  kappa  accuracy\n",
       "sen                           \n",
       "anger    0.62   0.07      0.63\n",
       "fear     0.67   0.15      0.57\n",
       "joy      0.65   0.18      0.54\n",
       "sadness  0.67   0.19      0.55"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_baseline"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
