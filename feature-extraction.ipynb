{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "08babe14-2b3e-4a4f-b4f9-76990bc4711c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.neural_network # Perceptón multicapa\n",
    "import sklearn.metrics # Métricas\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4f7d6a8-f798-44d6-a1c2-619d9953219b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def txt_to_df(file_name):   \n",
    "    with open(file_name, encoding=\"utf-8\") as f:\n",
    "        data = []\n",
    "        for l in f.read().split(\"\\n\")[:-1]:\n",
    "            o = {}\n",
    "            for k, v in enumerate(l.split(\"\\t\")):\n",
    "                col_name = \"id text sen int\".split()[k]\n",
    "                o[col_name] = v\n",
    "            data.append(o)\n",
    "    return pd.DataFrame(data).set_index(\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1571c39-4772-4303-8e11-4cb8480f2fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiments = \"anger fear joy sadness\".split()\n",
    "intensities = \"low medium high\".split()\n",
    "sentiment_map = {sentiments[x]:x for x in range(len(sentiments))}\n",
    "intensity_map = {intensities[x]:x for x in range(len(intensities))}\n",
    "\n",
    "root_data = \"assignment_1/data\"\n",
    "file_names = {\n",
    "    \"train/anger\": \"/train/anger-train.txt\",\n",
    "    \"train/fear\": \"/train/fear-train.txt\",\n",
    "    \"train/joy\": \"/train/joy-train.txt\",\n",
    "    \"train/sadness\": \"/train/sadness-train.txt\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2de19580-9983-432b-beeb-ef35519974e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame()\n",
    "for sen in sentiments:\n",
    "    file_name = root_data+file_names[f\"train/{sen}\"]\n",
    "    df_sen = txt_to_df(file_name)\n",
    "    df_train = pd.concat([df_train, df_sen], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0802e28-9101-4701-a493-d1f54b72160c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sen</th>\n",
       "      <th>int</th>\n",
       "      <th>sen_id</th>\n",
       "      <th>int_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td>How the fu*k! Who the heck! moved my fridge!.....</td>\n",
       "      <td>anger</td>\n",
       "      <td>high</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10001</th>\n",
       "      <td>So my Indian Uber driver just called someone t...</td>\n",
       "      <td>anger</td>\n",
       "      <td>high</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10002</th>\n",
       "      <td>@DPD_UK I asked for my parcel to be delivered ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>high</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10003</th>\n",
       "      <td>so ef whichever butt wipe pulled the fire alar...</td>\n",
       "      <td>anger</td>\n",
       "      <td>high</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10004</th>\n",
       "      <td>Don't join @BTCare they put the phone down on ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>high</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40855</th>\n",
       "      <td>Common app just randomly logged me out as I wa...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>high</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40856</th>\n",
       "      <td>I'd rather laugh with the rarest genius, in be...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>high</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40857</th>\n",
       "      <td>If you #invest in my new #film I will stop ask...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>medium</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40858</th>\n",
       "      <td>Just watched Django Unchained, Other people ma...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>low</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40859</th>\n",
       "      <td>@KeithOlbermann depressing how despicable Trum...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>high</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3960 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text      sen     int  \\\n",
       "id                                                                          \n",
       "10000  How the fu*k! Who the heck! moved my fridge!.....    anger    high   \n",
       "10001  So my Indian Uber driver just called someone t...    anger    high   \n",
       "10002  @DPD_UK I asked for my parcel to be delivered ...    anger    high   \n",
       "10003  so ef whichever butt wipe pulled the fire alar...    anger    high   \n",
       "10004  Don't join @BTCare they put the phone down on ...    anger    high   \n",
       "...                                                  ...      ...     ...   \n",
       "40855  Common app just randomly logged me out as I wa...  sadness    high   \n",
       "40856  I'd rather laugh with the rarest genius, in be...  sadness    high   \n",
       "40857  If you #invest in my new #film I will stop ask...  sadness  medium   \n",
       "40858  Just watched Django Unchained, Other people ma...  sadness     low   \n",
       "40859  @KeithOlbermann depressing how despicable Trum...  sadness    high   \n",
       "\n",
       "       sen_id  int_id  \n",
       "id                     \n",
       "10000       0       2  \n",
       "10001       0       2  \n",
       "10002       0       2  \n",
       "10003       0       2  \n",
       "10004       0       2  \n",
       "...       ...     ...  \n",
       "40855       3       2  \n",
       "40856       3       2  \n",
       "40857       3       1  \n",
       "40858       3       0  \n",
       "40859       3       2  \n",
       "\n",
       "[3960 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['sen_id'] = df_train['sen'].apply(lambda x: sentiment_map[x])\n",
    "df_train['int_id'] = df_train['int'].apply(lambda x: intensity_map[x])\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4a469d8-bdbc-47c6-a1c0-c0cddfe5c2bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How the fu*k! Who the heck! moved my fridge!... should I knock the landlord door. #angry #mad ##\n"
     ]
    }
   ],
   "source": [
    "print(df_train['text'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a568b15d-8630-4e70-8c72-0450dd454624",
   "metadata": {},
   "source": [
    "# Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85f5e40b-fbcd-4fd1-b62e-5da0fff4e4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import EnglishStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d72810f-61b9-4195-94fb-4aa8fc74e65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(tweet, steemer = EnglishStemmer()):\n",
    "    tweet = re.sub(r'@[^\\s]+', '', tweet)\n",
    "    splited_tweet = word_tokenize(tweet.lower())\n",
    "    steemed_tweet = \" \".join([steemer.stem(x) for x in splited_tweet])\n",
    "    return steemed_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f0d5078b-e1fa-4a2e-9e27-39cc2f350b50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sen</th>\n",
       "      <th>int</th>\n",
       "      <th>sen_id</th>\n",
       "      <th>int_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td>how the fu * k ! who the heck ! move my fridg ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>high</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10001</th>\n",
       "      <td>so my indian uber driver just call someon the ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>high</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10002</th>\n",
       "      <td>i ask for my parcel to be deliv to a pick up s...</td>\n",
       "      <td>anger</td>\n",
       "      <td>high</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10003</th>\n",
       "      <td>so ef whichev butt wipe pull the fire alarm in...</td>\n",
       "      <td>anger</td>\n",
       "      <td>high</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10004</th>\n",
       "      <td>do n't join they put the phone down on you , t...</td>\n",
       "      <td>anger</td>\n",
       "      <td>high</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40855</th>\n",
       "      <td>common app just random log me out as i was wri...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>high</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40856</th>\n",
       "      <td>i 'd rather laugh with the rarest genius , in ...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>high</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40857</th>\n",
       "      <td>if you # invest in my new # film i will stop a...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>medium</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40858</th>\n",
       "      <td>just watch django unchain , other peopl may fr...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>low</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40859</th>\n",
       "      <td>depress how despic trump , with no polici , ca...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>high</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3960 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text      sen     int  \\\n",
       "id                                                                          \n",
       "10000  how the fu * k ! who the heck ! move my fridg ...    anger    high   \n",
       "10001  so my indian uber driver just call someon the ...    anger    high   \n",
       "10002  i ask for my parcel to be deliv to a pick up s...    anger    high   \n",
       "10003  so ef whichev butt wipe pull the fire alarm in...    anger    high   \n",
       "10004  do n't join they put the phone down on you , t...    anger    high   \n",
       "...                                                  ...      ...     ...   \n",
       "40855  common app just random log me out as i was wri...  sadness    high   \n",
       "40856  i 'd rather laugh with the rarest genius , in ...  sadness    high   \n",
       "40857  if you # invest in my new # film i will stop a...  sadness  medium   \n",
       "40858  just watch django unchain , other peopl may fr...  sadness     low   \n",
       "40859  depress how despic trump , with no polici , ca...  sadness    high   \n",
       "\n",
       "       sen_id  int_id  \n",
       "id                     \n",
       "10000       0       2  \n",
       "10001       0       2  \n",
       "10002       0       2  \n",
       "10003       0       2  \n",
       "10004       0       2  \n",
       "...       ...     ...  \n",
       "40855       3       2  \n",
       "40856       3       2  \n",
       "40857       3       1  \n",
       "40858       3       0  \n",
       "40859       3       2  \n",
       "\n",
       "[3960 rows x 5 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_train\n",
    "df['text'] = df['text'].apply(lemmatize)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2a9ee8-d58a-4032-92d0-0d6552af7d0b",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e549b0c-7c3d-4ed7-bf7c-fb738e0486cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_elongations(text):\n",
    "    return {'elongations': len(re.findall(r\"(.)\\1{2}\", text))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "95888850-3efe-4833-9f18-2a394deb366d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_count(txt):\n",
    "    return {'tokens': len(word_tokenize(txt))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "adb9870c-2e80-40a7-ae07-4fce4884418b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vowel_count(text):\n",
    "    return {'vowels': len(re.findall(r\"[aeiou]\", text))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "373995cc-cf66-4d7a-83e2-d346f167df7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def const_count(text):\n",
    "    return {'const': len(re.findall(r\"[a-z-[aeiou]]\", text))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "21dfd7e4-48dc-4023-8d7b-339b8b1a96a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_negations(text):\n",
    "    return {'negations': len(re.findall(r\"^(?:never|no|nothing|nowhere|noone|none|not|havent|hasnt|hadnt|cant|couldnt|shouldnt|wont|wouldnt|dont|doesnt|didnt|isnt|arent|aint)|.*n't\", text))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "52a17e01-bd41-4a44-b1b9-44261981e496",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_emoticons(text):\n",
    "    regex = r\"(\\:\\w+\\:|\\<[\\/\\\\]?3|[\\(\\)\\\\\\D|\\*\\$][\\-\\^]?[\\:\\;\\=]|[\\:\\;\\=B8][\\-\\^]?[3DOPp\\@\\$\\*\\\\\\)\\(\\/\\|])(?=\\s|[\\!\\.\\?]|$)\"\n",
    "    return re.findall(regex, text)\n",
    "\n",
    "def emo_score(text):\n",
    "    posCount = 0\n",
    "    negCount = 0\n",
    "    totalCount = 0\n",
    "    totalScore = 0\n",
    "    emoticons =  get_emoticons(text)\n",
    "    for emo in emoticons:\n",
    "        totalCount+=1\n",
    "        if(emo.endswith(\"(\") or emo.endswith(\"[\") or emo.endswith(\"<\") or emo.endswith(\"/\") or emo.lower().endswith(\"c\") or emo.startswith(\")\") or emo.startswith(\"]\") or emo.startswith(\">\") or emo.startswith(\"\\\\\") or emo.startswith(\"D\")):\n",
    "            negCount+=1\n",
    "            totalScore = totalScore - 1\n",
    "        if(emo.endswith(\")\") or emo.endswith(\"]\") or emo.endswith(\">\") or emo.endswith(\"D\") or emo.startswith(\"(\") or emo.startswith(\"[\") or emo.startswith(\"<\") or emo.lower().startswith(\"c\")):\n",
    "            posCount+=1\n",
    "            totalScore = totalScore + 1\n",
    "            \n",
    "    return {'positiveEmo': posCount, 'negativeEmo': negCount, 'totalEmo': totalCount, 'scoreEmo': totalScore }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3422f180-4c40-42f5-b759-6d68eaf94146",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_marks(text):\n",
    "    return {'marks': len(re.findall(r\"!|\\?|\\*|\\.\\.+\", text))}    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "32f30ed4-0a14-4a6e-8818-28afb22784eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_hashtags(text):\n",
    "    return {'hashtags': len(re.findall(r\"# \\w+\", text))}    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1419a935-5ea7-460f-96dd-c4cf974f3c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "POSITIVE_WORDS = set(line.strip() for line in open('positive.txt'))\n",
    "NEGATIVE_WORDS = set(line.strip() for line in open('negative.txt'))\n",
    "\n",
    "def find_positive_negative_words(text):\n",
    "    words = text.split(\" \")\n",
    "    pos = 0\n",
    "    neg = 0\n",
    "    for word in words:\n",
    "        if word in NEGATIVE_WORDS:\n",
    "            neg += 1\n",
    "        elif word in POSITIVE_WORDS:\n",
    "            pos += 1\n",
    "    \n",
    "    return {'positive': pos, 'negative': neg}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8c546b09-de76-42b1-866d-6269ab76c6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_feature_map(text):\n",
    "    extractors = [search_elongations, search_negations, emo_score, search_marks, search_hashtags, find_positive_negative_words, token_count, vowel_count, const_count]\n",
    "    features = {}\n",
    "    for extractor in extractors:\n",
    "        features.update(extractor(text))\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e76e28ae-258e-461f-8e26-0b503ab13032",
   "metadata": {},
   "outputs": [],
   "source": [
    "datum = []\n",
    "features = []\n",
    "labels = [] \n",
    "\n",
    "for text, sen, intensity in zip(df.text, df.sen_id, df.int_id):\n",
    "    d = create_feature_map(text)\n",
    "    d.update({'sen': sen, 'int': intensity})\n",
    "    \n",
    "    datum.append(d)\n",
    "    features.append(d.values())\n",
    "    labels.append(sen)\n",
    "\n",
    "proccessed_df = pd.DataFrame(datum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f85dc815-512b-40e5-b737-00d65ef15963",
   "metadata": {},
   "outputs": [],
   "source": [
    "proccessed_df = shuffle(proccessed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "12c9d1c8-8766-4a29-914e-7581639d90f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>elongations</th>\n",
       "      <th>negations</th>\n",
       "      <th>positiveEmo</th>\n",
       "      <th>negativeEmo</th>\n",
       "      <th>totalEmo</th>\n",
       "      <th>scoreEmo</th>\n",
       "      <th>marks</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "      <th>tokens</th>\n",
       "      <th>vowels</th>\n",
       "      <th>const</th>\n",
       "      <th>sen</th>\n",
       "      <th>int</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3591</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1571</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1237</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1874</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1377</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2848</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2777</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2495</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3960 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      elongations  negations  positiveEmo  negativeEmo  totalEmo  scoreEmo  \\\n",
       "229             0          0            0            0         0         0   \n",
       "3591            0          0            0            0         0         0   \n",
       "1571            0          0            0            0         0         0   \n",
       "1237            0          0            0            0         1         0   \n",
       "1874            0          0            0            0         0         0   \n",
       "...           ...        ...          ...          ...       ...       ...   \n",
       "1377            0          0            0            0         0         0   \n",
       "484             0          0            0            0         0         0   \n",
       "2848            0          0            0            0         0         0   \n",
       "2777            0          0            0            0         0         0   \n",
       "2495            0          1            0            0         0         0   \n",
       "\n",
       "      marks  hashtags  positive  negative  tokens  vowels  const  sen  int  \n",
       "229       0         0         0         2      11      14      0    0    1  \n",
       "3591      0         1         0         3      10       8      0    3    1  \n",
       "1571      0         0         0         1       7      13      0    1    1  \n",
       "1237      1         3         1         2      26      30      0    1    1  \n",
       "1874      0         0         2         0      11      15      0    1    0  \n",
       "...     ...       ...       ...       ...     ...     ...    ...  ...  ...  \n",
       "1377      0         0         0         2      10      11      0    1    1  \n",
       "484       3         1         0         2      29      28      0    0    1  \n",
       "2848      0         0         0         0       3       7      0    2    0  \n",
       "2777      0         0         0         1      12      17      0    2    1  \n",
       "2495      0         0         1         0      23      28      0    2    1  \n",
       "\n",
       "[3960 rows x 15 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proccessed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1c272384-8c29-42ac-acb8-9a3029663ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ef603466-83be-4314-881a-b8bafea00a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_proccessed_df = proccessed_df[proccessed_df['sen'] == 0]\n",
    "\n",
    "features = sent_proccessed_df.iloc[:,:-1]\n",
    "labels = sent_proccessed_df.int\n",
    "\n",
    "data_features_train, data_features_test, data_label_train, data_label_test = sklearn.model_selection.train_test_split(\n",
    "    features,\n",
    "    labels,\n",
    "    test_size=0.2\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5970a255-48f2-4d58-ae5a-fde8d98ca6ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.18      0.24        34\n",
      "           1       0.67      0.89      0.76       125\n",
      "           2       0.29      0.07      0.11        30\n",
      "\n",
      "    accuracy                           0.63       189\n",
      "   macro avg       0.44      0.38      0.37       189\n",
      "weighted avg       0.56      0.63      0.56       189\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mlp = sklearn.neural_network.MLPClassifier(\n",
    "    hidden_layer_sizes = (50, 100, 200),\n",
    "    max_iter = 2000,\n",
    ")\n",
    "\n",
    "mlp.fit(\n",
    "    data_features_train,\n",
    "    data_label_train\n",
    ")\n",
    "\n",
    "print(sklearn.metrics.classification_report(\n",
    "    data_label_test,\n",
    "    mlp.predict(data_features_test)\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "76abf292-8360-48be-b892-7473d0059b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.18      0.26        34\n",
      "           1       0.68      0.91      0.78       125\n",
      "           2       0.22      0.07      0.10        30\n",
      "\n",
      "    accuracy                           0.65       189\n",
      "   macro avg       0.47      0.39      0.38       189\n",
      "weighted avg       0.57      0.65      0.58       189\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier()\n",
    "\n",
    "clf.fit(\n",
    "    data_features_train,\n",
    "    data_label_train\n",
    ")\n",
    "\n",
    "print(sklearn.metrics.classification_report(\n",
    "    data_label_test,\n",
    "    clf.predict(data_features_test)\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041ab6bd-4f2a-4934-9d6f-a09a6f1f53c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
